import streamlit as st
import cv2
import pytesseract
from PIL import Image, ImageOps
import numpy as np
import pandas as pd
import io
import re

pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

st.set_page_config(page_title="OCR HÃ³a Ä‘Æ¡n", layout="wide")
st.title("ğŸ“„ OCR HÃ³a Ä‘Æ¡n - TrÃ­ch xuáº¥t, Sá»­a & LÆ°u dá»¯ liá»‡u")

tab1, tab2 = st.tabs(["ğŸ“‚ Upload áº£nh", "ğŸ“· QuÃ©t tá»« Camera"])

# ---------- Tiá»n xá»­ lÃ½ áº£nh ----------
def preprocess(img_rgb, mode="clahe_otsu"):
    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)

    h, w = gray.shape
    max_side = max(h, w)
    if max_side < 1800:
        scale = 1800 / max_side
        gray = cv2.resize(gray, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)

    gray = cv2.fastNlMeansDenoising(gray, h=10, templateWindowSize=7, searchWindowSize=21)

    if mode == "clahe_otsu":
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
        g2 = clahe.apply(gray)
        bin_img = cv2.threshold(g2, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
    elif mode == "adaptive":
        bin_img = cv2.adaptiveThreshold(
            gray, 255,
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY, 31, 5
        )
    else:
        bin_img = gray

    return bin_img

# ---------- OCR ----------
def run_ocr(image_bin, psm):
    config = f"--oem 1 --psm {psm} -c preserve_interword_spaces=1"
    text = pytesseract.image_to_string(image_bin, lang="vie+eng", config=config)
    data = pytesseract.image_to_data(image_bin, lang="vie+eng", config=config, output_type=pytesseract.Output.DATAFRAME)
    if "conf" in data.columns:
        confs = data["conf"]
        confs = confs[confs.astype(str) != "-1"]
        mean_conf = float(confs.astype(float).mean()) if len(confs) else -1.0
    else:
        mean_conf = -1.0
    return text, mean_conf

# ---------- TrÃ­ch xuáº¥t thÃ´ng tin ----------
def extract_info(text):
    # --- Sá»‘ hÃ³a Ä‘Æ¡n ---
    patterns_hd = [
        r'hÃ³a\s*Ä‘Æ¡n\s*#\s*(\d+)',
        r'hÃ³a\s*Ä‘Æ¡n\s*sá»‘\s*[:\s]*(\d+)',
        r'hÃ³a\s*Ä‘Æ¡n\s*[:\s]*(\d+)',
        r'#\s*(\d+)',
        r'sá»‘\s*[:\s]*(\d+)',
        r'H[ÄD]?\s*(\d+)',
        r'Invoice\s*#\s*(\d+)'
    ]
    so_hd = None
    for p in patterns_hd:
        m = re.search(p, text, re.IGNORECASE)
        if m:
            so_hd = m.group(1)
            break

    # --- NgÃ y ---
    patterns_ngay = [
        r'ngÃ y\s+(\d{1,2}\s+thÃ¡ng\s+\d{1,2}\s+nÄƒm\s+\d{4})',
        r'(\d{1,2}\s+thÃ¡ng\s+\d{1,2}\s+nÄƒm\s+\d{4})',
        r'(\d{1,2}[/-]\d{1,2}[/-]\d{2,4})',
        r'(\d{1,2}[.]\d{1,2}[.]\d{2,4})',
        r'ngÃ y\s*[:]\s*(\d{1,2}\s*thÃ¡ng\s*\d{1,2}\s*nÄƒm\s*\d{4})'
    ]
    ngay = None
    for p in patterns_ngay:
        m = re.search(p, text, re.IGNORECASE)
        if m:
            date_str = m.group(1)
            if 'thÃ¡ng' in date_str and 'nÄƒm' in date_str:
                parts = re.findall(r'\d+', date_str)
                if len(parts) >= 3:
                    day, month, year = parts[0], parts[1], parts[2]
                    ngay = f"{day.zfill(2)}/{month.zfill(2)}/{year}"
            else:
                ngay = date_str
            break

    # --- Tá»•ng tiá»n ---
    patterns_tong = [
        r'Tá»•ng\s*thanh\s*toÃ¡n\s*[:\s]*([\d.,]+)\s*[Ä‘ÄkK]?',
        r'Tá»•ng\s*cá»™ng\s*[:\s]*([\d.,]+)\s*[Ä‘ÄkK]?',
        r'Tiá»n\s*thanh\s*toÃ¡n\s*[:\s]*([\d.,]+)\s*[Ä‘ÄkK]?'
    ]
    tong_tien = None
    for pattern in patterns_tong:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            number_str = match.group(1)
            clean_number = re.sub(r'[^\d]', '', number_str)
            full_match = match.group(0).lower()
            try:
                amount = float(clean_number)
                if 'k' in full_match and 'Ä‘' not in full_match:
                    amount *= 1000
                tong_tien = f"{amount:,.0f}Ä‘".replace(",", ".")
                break
            except:
                continue

    # --- Äá»‹a chá»‰ ---
    patterns_dia_chi = [
        r'Ä‘á»‹a\s*chá»‰\s*khÃ¡ch\s*hÃ ng\s*[:\s]*([^\n\r]{10,100})',
        r'(\d+\s+Ä‘iá»‡n\s+biÃªn[^\n\r]*)',
        r'(\d+\s+Ä‘Æ°á»ng\s+[a-zA-Z0-9\s]+[^\n\r]*)',
        r'(sá»‘\s+\d+[^\n\r]{10,80})'
    ]
    dia_chi = None
    for p in patterns_dia_chi:
        m = re.search(p, text, re.IGNORECASE)
        if m:
            dia_chi = m.group(1).strip()
            break

    return {
        "Sá»‘ hÃ³a Ä‘Æ¡n": so_hd if so_hd else "",
        "NgÃ y": ngay if ngay else "",
        "Tá»•ng tiá»n": tong_tien if tong_tien else "",
        "Äá»‹a chá»‰": dia_chi if dia_chi else ""
    }

# ---------- Xá»­ lÃ½ áº£nh ----------
def process_image(pil_img):
    pil = ImageOps.exif_transpose(pil_img).convert("RGB")
    img_rgb = np.array(pil)

    bin1 = preprocess(img_rgb, mode="clahe_otsu")
    bin2 = preprocess(img_rgb, mode="adaptive")

    candidates = []
    for bin_img, prep_name in [(bin1, "CLAHE+Otsu"), (bin2, "Adaptive")]:
        for psm in [6, 4, 11]:
            txt, score = run_ocr(bin_img, psm)
            candidates.append({
                "prep": prep_name,
                "psm": psm,
                "text": txt,
                "score": score,
                "img": bin_img
            })
    best = max(candidates, key=lambda x: x["score"])
    return pil, best

# ---------- Hiá»ƒn thá»‹ ----------
def show_results(pil, best):
    col1, col2 = st.columns([2,3])
    with col1:
        st.subheader("ğŸ–¼ áº¢nh hÃ³a Ä‘Æ¡n & áº£nh xá»­ lÃ½")
        st.image(pil, caption="áº¢nh gá»‘c", use_container_width=True)
        st.image(best["img"], caption=f"Xá»­ lÃ½ tá»‘t nháº¥t: {best['prep']} | PSM {best['psm']}", use_container_width=True, channels="GRAY")
    with col2:
        st.subheader("ğŸ“‘ VÄƒn báº£n OCR")
        st.caption(f"Cháº¿ Ä‘á»™: {best['prep']} | PSM {best['psm']} | Äá»™ tin cáº­y TB: {round(best['score'],2)}")

        # --- VÃ¹ng chá»‰nh sá»­a text OCR ---
        ocr_text = st.text_area("Káº¿t quáº£ OCR (cÃ³ thá»ƒ sá»­a)", value=best["text"], height=300)

        # --- NÃºt táº£i vÄƒn báº£n OCR ---
        st.download_button(
            "â¬‡ï¸ Táº£i vÄƒn báº£n OCR",
            ocr_text,
            file_name="van_ban_ocr.txt",
            mime="text/plain"
        )
        st.markdown("---")
        
        # --- TrÃ­ch xuáº¥t thÃ´ng tin ---
        info = extract_info(ocr_text)

        st.subheader("ğŸ“‹ ThÃ´ng tin trÃ­ch xuáº¥t (cÃ³ thá»ƒ sá»­a)")
        # Cho phÃ©p sá»­a tá»«ng trÆ°á»ng
        info["Sá»‘ hÃ³a Ä‘Æ¡n"] = st.text_input("Sá»‘ hÃ³a Ä‘Æ¡n", value=info["Sá»‘ hÃ³a Ä‘Æ¡n"])
        info["NgÃ y"] = st.text_input("NgÃ y", value=info["NgÃ y"])
        info["Tá»•ng tiá»n"] = st.text_input("Tá»•ng tiá»n", value=info["Tá»•ng tiá»n"])
        info["Äá»‹a chá»‰"] = st.text_input("Äá»‹a chá»‰", value=info["Äá»‹a chá»‰"])

        # --- Xuáº¥t dá»¯ liá»‡u ---
        df_out = pd.DataFrame([info])

        # CSV
        csv_buffer = io.StringIO()
        df_out.to_csv(csv_buffer, index=False, encoding="utf-8-sig")
        st.download_button("â¬‡ï¸ Táº£i CSV", data=csv_buffer.getvalue(), file_name="hoadon_ocr.csv", mime="text/csv")

        # Excel
        excel_buffer = io.BytesIO()
        with pd.ExcelWriter(excel_buffer, engine="xlsxwriter") as writer:
            df_out.to_excel(writer, index=False, sheet_name="OCR")
        excel_buffer.seek(0)
        st.download_button("â¬‡ï¸ Táº£i Excel", data=excel_buffer.getvalue(), file_name="hoadon_ocr.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

# ============ Upload áº£nh ============
with tab1:
    uploaded_file = st.file_uploader("Táº£i áº£nh hÃ³a Ä‘Æ¡n lÃªn", type=["png","jpg","jpeg"])
    if uploaded_file is not None:
        pil = Image.open(uploaded_file)
        pil, best = process_image(pil)
        show_results(pil, best)

# ============ QuÃ©t Camera ============
with tab2:
    cam_file = st.camera_input("Chá»¥p áº£nh hÃ³a Ä‘Æ¡n báº±ng camera")
    if cam_file is not None:
        pil = Image.open(cam_file)
        pil, best = process_image(pil)
        show_results(pil, best)